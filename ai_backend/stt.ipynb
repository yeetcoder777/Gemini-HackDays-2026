{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ee1a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\Hacksync\\hacksync2026\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from fastapi import FastAPI, WebSocket\n",
    "import numpy as np\n",
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0c16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "986caaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "BUFFER_SECONDS = 2.0  # run whisper every 2s\n",
    "MIN_SAMPLES = int(SAMPLE_RATE * BUFFER_SECONDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b034f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\Hacksync\\hacksync2026\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--Systran--faster-whisper-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "model = WhisperModel(\"base\", device=\"cpu\", compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48062631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_float32(audio: np.ndarray) -> str:\n",
    "    \"\"\"\n",
    "    audio: float32 mono [-1,1] at 16kHz\n",
    "    returns transcript text\n",
    "    \"\"\"\n",
    "    segments, info = model.transcribe(audio, language=\"en\")\n",
    "    return \"\".join([s.text for s in segments]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stt_stream(ws: WebSocket):\n",
    "  await ws.accept()\n",
    "\n",
    "  # We'll store audio as float32 in a python list then convert to np array\n",
    "  audio_samples = []\n",
    "  last_text = \"\"\n",
    "\n",
    "  try:\n",
    "      while True:\n",
    "          # frontend sends raw PCM16\n",
    "          pcm_bytes = await ws.receive_bytes()\n",
    "\n",
    "          # bytes -> int16 -> float32\n",
    "          pcm = np.frombuffer(pcm_bytes, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "          audio_samples.extend(pcm.tolist())\n",
    "\n",
    "          # whenever buffer gets >= 2 sec, transcribe\n",
    "          if len(audio_samples) >= MIN_SAMPLES:\n",
    "              audio_np = np.array(audio_samples, dtype=np.float32)\n",
    "\n",
    "              # run whisper in background thread so websocket stays responsive\n",
    "              text = await asyncio.to_thread(transcribe_float32, audio_np)\n",
    "\n",
    "              if text and text != last_text:\n",
    "                  last_text = text\n",
    "                  await ws.send_json({\"text\": text, \"is_final\": False})\n",
    "\n",
    "              # keep last 0.5 sec overlap (prevents cutting words)\n",
    "              keep = int(SAMPLE_RATE * 0.5)\n",
    "              audio_samples = audio_samples[-keep:]\n",
    "\n",
    "  except Exception:\n",
    "      # connection closed: final transcript\n",
    "      if audio_samples:\n",
    "          audio_np = np.array(audio_samples, dtype=np.float32)\n",
    "          final_text = await asyncio.to_thread(transcribe_float32, audio_np)\n",
    "          await ws.send_json({\"text\": final_text, \"is_final\": True})\n",
    "      await ws.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363b92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
